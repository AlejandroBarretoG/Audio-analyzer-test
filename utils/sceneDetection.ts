
import { SubtitleNode } from "../types";

// CONFIGURATION
const ANALYSIS_WIDTH = 128; // Optimized width as requested
const ANALYSIS_HEIGHT = 72; // Maintain roughly 16:9 aspect ratio
const FPS_TO_CHECK = 2; // Check every 0.5 seconds
const SAMPLING_RATE = 1 / FPS_TO_CHECK; 
const DEFAULT_THRESHOLD = 15; // Sensitivity threshold (0-100). Lower = more sensitive.

interface FrameSignature {
  avgLuminance: number;
  histogram: number[]; // Reduced depth color histogram
}

/**
 * Detects visual scene cuts using Histogram & Luminance Difference.
 * Implements the specific algorithm described:
 * 1. Resize to 128px wide.
 * 2. Calculate Luminance (70% weight) and Color Histogram (30% weight).
 * 3. Compare signatures to detect cuts.
 */
export const detectScenes = async (
  videoFile: File, 
  onProgress: (percentage: number) => void,
  threshold: number = DEFAULT_THRESHOLD
): Promise<SubtitleNode[]> => {
  
  return new Promise((resolve, reject) => {
    const video = document.createElement('video');
    const canvas = document.createElement('canvas');
    // Optimization: willReadFrequently
    const ctx = canvas.getContext('2d', { willReadFrequently: true });
    
    if (!ctx) {
      reject(new Error("Could not create canvas context"));
      return;
    }

    // Optimization: Downscale resolution
    canvas.width = ANALYSIS_WIDTH;
    canvas.height = ANALYSIS_HEIGHT;

    const url = URL.createObjectURL(videoFile);
    video.src = url;
    video.muted = true;
    video.playsInline = true;
    video.crossOrigin = "anonymous";

    const scenes: SubtitleNode[] = [];
    
    let prevSignature: FrameSignature | null = null;
    let lastCutTime = 0;
    
    // Temporary storage for the start frame of the current scene
    let currentSceneThumbnail: string | null = null;

    const seekTo = (time: number): Promise<void> => {
      return new Promise((resolveSeek) => {
        const onSeeked = () => {
          video.removeEventListener('seeked', onSeeked);
          resolveSeek();
        };
        video.addEventListener('seeked', onSeeked);
        video.currentTime = time;
      });
    };

    video.onloadedmetadata = async () => {
      const duration = video.duration;
      let currentTime = 0;
      
      try {
        // 1. Analysis Loop
        while (currentTime < duration) {
          await seekTo(currentTime);

          // Draw frame
          ctx.drawImage(video, 0, 0, ANALYSIS_WIDTH, ANALYSIS_HEIGHT);
          const imageData = ctx.getImageData(0, 0, ANALYSIS_WIDTH, ANALYSIS_HEIGHT);

          // 2. Calculate Signature
          const signature = getFrameSignature(imageData);

          // Capture the very first frame as the start of the first scene
          if (currentTime === 0) {
            currentSceneThumbnail = canvas.toDataURL('image/jpeg', 0.7);
            prevSignature = signature;
            currentTime += SAMPLING_RATE;
            continue;
          }

          // 3. Compare with previous
          if (prevSignature) {
            const diff = getFrameDiff(prevSignature, signature);
            
            // 4. Threshold Check
            // Ensure min scene length of 1s to avoid flicker
            if (diff > threshold && (currentTime - lastCutTime) >= 1.0) {
              
              // SCENE DETECTED!
              // The *previous* scene ended here.
              
              scenes.push({
                id: crypto.randomUUID(),
                timestamp: lastCutTime,
                endTime: currentTime,
                type: 'scene',
                text: `Visual Scene ${scenes.length + 1}`,
                thumbnail: currentSceneThumbnail || undefined,
                isAutoGenerated: true
              });

              // Reset for new scene
              lastCutTime = currentTime;
              // Capture thumbnail for the NEW scene starting now
              currentSceneThumbnail = canvas.toDataURL('image/jpeg', 0.7);
            }
          }

          prevSignature = signature;
          
          // Progress
          const progress = Math.round((currentTime / duration) * 100);
          onProgress(progress);

          currentTime += SAMPLING_RATE;
        }

        // Add the final scene
        if (lastCutTime < duration) {
          scenes.push({
             id: crypto.randomUUID(),
             timestamp: lastCutTime,
             endTime: duration,
             type: 'scene',
             text: `Visual Scene ${scenes.length + 1}`,
             thumbnail: currentSceneThumbnail || undefined,
             isAutoGenerated: true
          });
        }

        resolve(scenes);

      } catch (error) {
        console.error("Scene detection error:", error);
        reject(error);
      } finally {
        URL.revokeObjectURL(url);
        video.remove();
        canvas.remove();
      }
    };

    video.onerror = () => {
      URL.revokeObjectURL(url);
      reject(new Error("Error loading video file"));
    };
  });
};

/**
 * Calculates Frame Signature: Average Luminance + Color Histogram
 */
function getFrameSignature(imageData: ImageData): FrameSignature {
  const data = imageData.data;
  const pixelCount = data.length / 4;
  
  let totalLum = 0;
  
  // Reduced depth histogram (4 bits per channel = 64 bins total is a bit complex for a single array, 
  // so we'll do 3 separate histograms of 16 bins each for R, G, B).
  // Text said "reduces color depth (4 bits per channel)". 
  // 4 bits = 16 values (0-15). 
  const rHist = new Array(16).fill(0);
  const gHist = new Array(16).fill(0);
  const bHist = new Array(16).fill(0);

  for (let i = 0; i < data.length; i += 4) {
    const r = data[i];
    const g = data[i + 1];
    const b = data[i + 2];

    // Luminance standard formula
    const lum = 0.299 * r + 0.587 * g + 0.114 * b;
    totalLum += lum;

    // Histogram (reduce 0-255 to 0-15)
    // r >> 4 is equivalent to Math.floor(r / 16)
    rHist[r >> 4]++;
    gHist[g >> 4]++;
    bHist[b >> 4]++;
  }

  // Normalize Histogram (so it sums to 1, effectively probability distribution)
  const normalize = (hist: number[]) => hist.map(v => v / pixelCount);

  return {
    avgLuminance: totalLum / pixelCount,
    histogram: [...normalize(rHist), ...normalize(gHist), ...normalize(bHist)]
  };
}

/**
 * Calculates weighted difference between two signatures.
 * Weight: 70% Luminance Diff, 30% Histogram Diff
 * Returns a score roughly 0-100.
 */
function getFrameDiff(sig1: FrameSignature, sig2: FrameSignature): number {
  // 1. Luminance Diff (0-255 range usually, normalize to percentage 0-100)
  const lumDiff = Math.abs(sig1.avgLuminance - sig2.avgLuminance);
  // Max lum diff is 255. Normalize to 0-1.
  const lumScore = (lumDiff / 255); 

  // 2. Histogram Diff (Manhattan Distance or Euclidean)
  // Since they are normalized 0-1, max sum difference is 2 (if completely non-overlapping).
  // We compare bin by bin.
  let histDiffSum = 0;
  for (let i = 0; i < sig1.histogram.length; i++) {
    histDiffSum += Math.abs(sig1.histogram[i] - sig2.histogram[i]);
  }
  // Normalize roughly. With 3 channels * 2 max diff = 6. 
  // Let's average the channel diffs.
  // Actually, since we concatenated R, G, B arrays, length is 48.
  // Max possible diff is 2 per channel (1 in A, 0 in B => diff 1. 0 in A, 1 in B => diff 1. Sum 2).
  // So max total is 6.
  const histScore = histDiffSum / 6;

  // 3. Weighted Combination
  // Weights: 0.7 Luminance, 0.3 Histogram
  const weightedDiff = (lumScore * 0.7) + (histScore * 0.3);

  // Return as 0-100 scale
  return weightedDiff * 100;
}
